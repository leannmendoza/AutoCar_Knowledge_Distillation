{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFNyNIHyttt5"
      },
      "outputs": [],
      "source": [
        " # python standard libraries\n",
        "import os\n",
        "import random\n",
        "import fnmatch\n",
        "import datetime\n",
        "import pickle\n",
        "\n",
        "# data processing\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.width', 300)\n",
        "pd.set_option('display.float_format', '{:,.4f}'.format)\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# sklearn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# imaging\n",
        "import cv2\n",
        "from imgaug import augmenters as img_aug\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "\n",
        "# ml models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kqMK_M8kaje"
      },
      "outputs": [],
      "source": [
        "def create_data_sets(data_dir, visual=False):\n",
        "\n",
        "  # Place images into pandas dataframe\n",
        "  file_list = os.listdir(data_dir)\n",
        "  image_paths = []\n",
        "  steering_angles = []\n",
        "  pattern = \"*.png\"\n",
        "  for filename in file_list:\n",
        "      if fnmatch.fnmatch(filename, pattern):\n",
        "          image_paths.append(os.path.join(data_dir,filename))\n",
        "          angle = filename.split('_')[2].split('.')[0].split(' ')[0]  # 092 part of video01_143_092.png is the angle. 90 is go straight\n",
        "          steering_angles.append(int(angle))\n",
        "\n",
        "  df = pd.DataFrame()\n",
        "  df['ImagePath'] = image_paths\n",
        "  df['Angle'] = steering_angles\n",
        "\n",
        "  # Look at the distribution of steering angle\n",
        "  num_of_bins = 25\n",
        "  samples_per_bin = 400\n",
        "  hist, bins = np.histogram(df['Angle'], num_of_bins)\n",
        "\n",
        "  if visual:\n",
        "    fig, axes = plt.subplots(1,1, figsize=(12,4))\n",
        "    axes.hist(df['Angle'], bins=num_of_bins, width=1, color='blue')\n",
        "\n",
        "\n",
        "  # Split training from testing data\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(image_paths, steering_angles, test_size=0.15) #split data 85% training, 15% testing\n",
        "\n",
        "  if visual:\n",
        "    print(\"Training data: %d\\nTesting data: %d\" % (len(X_train), len(X_test)))\n",
        "    # plot the distributions of train and valid, make sure they are consistent\n",
        "    fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
        "    axes[0].hist(Y_train, bins=num_of_bins, width=1, color='blue')\n",
        "    axes[0].set_title('Training Data')\n",
        "    axes[1].hist(Y_test, bins=num_of_bins, width=1, color='red')\n",
        "    axes[1].set_title('Testing Data')\n",
        "\n",
        "\n",
        "  # Split validation from  testing data\n",
        "  X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.10) #split data training-validation\n",
        "\n",
        "  if visual:\n",
        "    print(\"Training data: %d\\nValidation data: %d\" % (len(X_train), len(X_valid)))\n",
        "    # plot the distributions of train and valid, make sure they are consistent\n",
        "    fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
        "    axes[0].hist(Y_train, bins=num_of_bins, width=1, color='blue')\n",
        "    axes[0].set_title('Training Data')\n",
        "    axes[1].hist(Y_test, bins=num_of_bins, width=1, color='red')\n",
        "    axes[1].set_title('Validation Data')\n",
        "\n",
        "\n",
        "  return X_train, Y_train, X_valid, Y_valid, X_test, Y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_9x_MKenA0M"
      },
      "outputs": [],
      "source": [
        "\n",
        "def augment_images_for_preprocessing(X_train, Y_train, X_valid, Y_valid, X_test, Y_test):\n",
        "  \"\"\"\n",
        "  Methods containing random number generation use seed function to replicate\n",
        "  controlled data sets during trials\n",
        "  \"\"\"\n",
        "  def my_imread(image_path):\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      return image\n",
        "\n",
        "  def zoom(image):\n",
        "      zoom = img_aug.Affine(scale=(1, 1.3))  # zoom from 100% (no zoom) to 130%\n",
        "      image = zoom.augment_image(image)\n",
        "      return image\n",
        "\n",
        "  def pan(image):\n",
        "      # pan left / right / up / down about 10%\n",
        "      pan = img_aug.Affine(translate_percent= {\"x\" : (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "      image = pan.augment_image(image)\n",
        "      return image\n",
        "\n",
        "  def adjust_brightness(image):\n",
        "      # increase or decrease brightness by 30%\n",
        "      brightness = img_aug.Multiply((0.7, 1.3))\n",
        "      image = brightness.augment_image(image)\n",
        "      return image\n",
        "\n",
        "  def blur(image):\n",
        "      kernel_size = random.randint(1, 5)  # kernel larger than 5 would make the image way too blurry\n",
        "      image = cv2.blur(image,(kernel_size, kernel_size))\n",
        "\n",
        "      return image\n",
        "\n",
        "  def random_flip(image, steering_angle):\n",
        "      is_flip = random.randint(0, 1)\n",
        "      if is_flip == 1:\n",
        "          # randomly flip horizon\n",
        "          image = cv2.flip(image,1)\n",
        "          steering_angle = 180 - steering_angle\n",
        "\n",
        "      return image, steering_angle\n",
        "\n",
        "  def random_augment(image, steering_angle):\n",
        "      \"\"\"\n",
        "      Randomly augment images by panning, zooming, blurring, and adjusting brightness\n",
        "      \"\"\"\n",
        "      if np.random.rand() < 0.5:\n",
        "          image = pan(image)\n",
        "      if np.random.rand() < 0.5:\n",
        "          image = zoom(image)\n",
        "      if np.random.rand() < 0.5:\n",
        "          image = blur(image)\n",
        "      if np.random.rand() < 0.5:\n",
        "          image = adjust_brightness(image)\n",
        "      image, steering_angle = random_flip(image, steering_angle)\n",
        "\n",
        "      return image, steering_angle\n",
        "\n",
        "  def img_preprocess(image):\n",
        "      height, _, _ = image.shape\n",
        "      image = image[int(height/2):,:,:]   # remove top half of the image, as it is not relavant for lane following\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)  # Nvidia model said it is best to use YUV color space\n",
        "      image = cv2.GaussianBlur(image, (3,3), 0)\n",
        "      image = cv2.resize(image, (200,66)) # input image size (200,66) Nvidia model\n",
        "      image = image / 255                 # normalizing\n",
        "      return image\n",
        "\n",
        "  def image_data_generator(image_paths, steering_angles, batch_size, is_training):\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_steering_angles = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            random_index = random.randint(0, len(image_paths) - 1)\n",
        "            image_path = image_paths[random_index]\n",
        "            image = my_imread(image_paths[random_index])\n",
        "            steering_angle = steering_angles[random_index]\n",
        "            if is_training:\n",
        "                # training: augment image\n",
        "                image, steering_angle = random_augment(image, steering_angle)\n",
        "\n",
        "            image = img_preprocess(image)\n",
        "            batch_images.append(image)\n",
        "            batch_steering_angles.append(steering_angle)\n",
        "\n",
        "        yield( np.asarray(batch_images), np.asarray(batch_steering_angles))\n",
        "\n",
        "  # Create processed image test sets (ppi = pre-processed images)\n",
        "  X_train_ppi, Y_train_ppi = next(image_data_generator(X_train, Y_train, len(X_train), True))\n",
        "  X_valid_ppi, Y_valid_ppi = next(image_data_generator(X_valid, Y_valid, len(X_valid), True))\n",
        "  X_test_ppi, Y_test_ppi = next(image_data_generator(X_test, Y_test, len(X_test), False))\n",
        "\n",
        "  return X_train_ppi, Y_train_ppi, X_valid_ppi, Y_valid_ppi, X_test_ppi, Y_test_ppi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8UmNy1Kqz4o"
      },
      "outputs": [],
      "source": [
        "def load_model(path_to_model):\n",
        "  return keras.models.load_model(path_to_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUuuWJvtsamX"
      },
      "outputs": [],
      "source": [
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super(Distiller, self).__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        alpha=0.1,\n",
        "        temperature=3,\n",
        "    ):\n",
        "        \"\"\" Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass of teacher\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student\n",
        "            student_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "\n",
        "            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531\n",
        "            # The magnitudes of the gradients produced by the soft targets scale\n",
        "            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.\n",
        "            distillation_loss = (\n",
        "                self.distillation_loss_fn(\n",
        "                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                    tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
        "                )\n",
        "                * self.temperature**2\n",
        "            )\n",
        "\n",
        "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update(\n",
        "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
        "        )\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "\n",
        "        # Return a dict of performance\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"student_loss\": student_loss})\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOdSZeu8sg6g"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def summarize_prediction(Y_true, Y_pred):\n",
        "\n",
        "    mse = mean_squared_error(Y_true, Y_pred)\n",
        "    r_squared = r2_score(Y_true, Y_pred)\n",
        "\n",
        "    print(f'mse       = {mse:.2f}')\n",
        "    print(f'r_squared = {r_squared:.2%}')\n",
        "    print()\n",
        "    return mse, r_squared\n",
        "\n",
        "def predict_and_summarize(X, Y, model):\n",
        "    Y_pred = model.predict(X)\n",
        "    mse, r_squared = summarize_prediction(Y, Y_pred)\n",
        "    return mse, r_squared\n",
        "\n",
        "def evaluate_and_summarize(X, Y, model):\n",
        "    Y_pred = model.predict(X)\n",
        "    mse, r_squared = summarize_prediction(Y, Y_pred)\n",
        "    return mse, r_squared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0toNZDrBwSEp"
      },
      "outputs": [],
      "source": [
        "def distilled0_model():\n",
        "    model = keras.models.Sequential(name='distilled0_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(12, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(24, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPxBBr1kOQ4C"
      },
      "outputs": [],
      "source": [
        "def distilled1_model():\n",
        "    model = keras.models.Sequential(name='distilled1_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(36, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LReL4NTyOXTo"
      },
      "outputs": [],
      "source": [
        "def distilled2_model():\n",
        "    model = keras.models.Sequential(name='distilled2_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(36, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(48, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTyW8hajOiEB"
      },
      "outputs": [],
      "source": [
        "def distilled3_model():\n",
        "    model = keras.models.Sequential(name='distilled3_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(48, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12GOfsfuWwe_"
      },
      "outputs": [],
      "source": [
        "def distilled4_model():\n",
        "    model = keras.models.Sequential(name='distilled4_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(12, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(36, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hXJ0ld9WzGD"
      },
      "outputs": [],
      "source": [
        " def distilled5_model():\n",
        "    model = keras.models.Sequential(name='distilled5_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(12, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(48, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmmlMWX6-AH7"
      },
      "outputs": [],
      "source": [
        " def distilled6_model():\n",
        "    model = keras.models.Sequential(name='distilled6_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(12, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQOTs7mO-RyG"
      },
      "outputs": [],
      "source": [
        " def distilled7_model():\n",
        "    model = keras.models.Sequential(name='distilled7_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(48, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRC0EZ3gPG2U"
      },
      "outputs": [],
      "source": [
        "def distilled8_model():\n",
        "    model = keras.models.Sequential(name='distilled8_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(24, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TuKMLR7PM4T"
      },
      "outputs": [],
      "source": [
        "def distilled9_model():\n",
        "    model = keras.models.Sequential(name='distilled9_model')\n",
        "\n",
        "    # elu=Expenential Linear Unit, similar to leaky Relu\n",
        "\n",
        "    # Convolution Layers\n",
        "    model.add(keras.layers.Conv2D(36, (5, 5), strides=(2, 2), input_shape=(66, 200, 3), activation='elu'))\n",
        "    model.add(keras.layers.Conv2D(64, (3, 3), activation='elu'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(keras.layers.Flatten())\n",
        "\n",
        "    # output layer: turn angle (from 45-135, 90 is straight, <90 turn left, >90 turn right)\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    # since this is a regression problem not classification problem,\n",
        "    # we use MSE (Mean Squared Error) as loss function\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(loss='mse', optimizer=optimizer)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lsZii8Nx82w"
      },
      "outputs": [],
      "source": [
        "def distill_teacher_to_student(student, teacher, temp, X_train_ppi, Y_train_ppi, X_valid_ppi, Y_valid_ppi):\n",
        "  \"\"\"\n",
        "  Distill teacher model into student model\n",
        "\n",
        "  :student: points to defined student model architecture\n",
        "  :teacher: points to trained teacher model\n",
        "  :temp: temperature to perform the distillations\n",
        "  :X_train_ppi: training preprocessed images\n",
        "  :Y_train_ppi: training preprocessed angles\n",
        "  :X_valid_ppi: validation preprocessed images\n",
        "  :Y_valid_ppi: validation preprocessed angles\n",
        "  \"\"\"\n",
        "  # Initialize and compile distiller\n",
        "  distilled = Distiller(student=student, teacher=teacher)\n",
        "  distilled.compile(\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "      student_loss_fn=tf.keras.losses.MeanSquaredError(),\n",
        "      distillation_loss_fn=tf.keras.losses.MeanSquaredError(),\n",
        "      alpha=0.1,\n",
        "      temperature=temp,\n",
        "  )\n",
        "  # Distill teacher to student\n",
        "  distilled.fit(x=X_train_ppi, y=Y_train_ppi,\n",
        "                steps_per_epoch=10,\n",
        "                epochs=40,\n",
        "                validation_data = (X_valid_ppi, Y_valid_ppi),\n",
        "                verbose=1,\n",
        "                shuffle=1)\n",
        "  return distilled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8i5XLstUz2N"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "def write_row_csv(data, csv_file):\n",
        "  \"\"\"\n",
        "  Write a row into a csv file\n",
        "\n",
        "  :param data: data to write into file\n",
        "  :param csv_file: file youd like to write data into\n",
        "  :return: none\n",
        "  \"\"\"\n",
        "  with open(csv_file, 'a') as outfile:\n",
        "    writer = csv.writer(outfile)\n",
        "    writer.writerow(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_WBWsd6cksr"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "  # Access data\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  # change the data path on own google drive\n",
        "  data_dir = '/content/drive/MyDrive/data/train_data/'\n",
        "\n",
        "  # Create datasets\n",
        "  X_train, Y_train, X_valid, Y_valid, X_test, Y_test = create_data_sets(data_dir)\n",
        "  X_train_ppi, Y_train_ppi, X_valid_ppi, Y_valid_ppi, X_test_ppi, Y_test_ppi = augment_images_for_preprocessing(X_train, Y_train, X_valid, Y_valid, X_test, Y_test)\n",
        "\n",
        "  \"\"\"\n",
        "  # For first run save images to ensure each run has the same datasets\n",
        "  np.savetxt('X_train_ppi.csv', X_train_ppi, delimiter=',')\n",
        "  np.savetxt('Y_train_ppi.csv', Y_train_ppi, delimiter=',')\n",
        "  np.savetxt('X_valid_ppi.csv', X_valid_ppi, delimiter=',')\n",
        "  np.savetxt('Y_valid_ppi.csv', Y_valid_ppi, delimiter=',')\n",
        "  np.savetxt('X_test_ppi.csv', X_test_ppi, delimiter=',')\n",
        "  np.savetxt('Y_test_ppi.csv', Y_test_ppi, delimiter=',')\n",
        "  \"\"\"\n",
        "#have a look LeAnn 's teacher model and generate own or use it\n",
        "  # Load trained teacher model\n",
        "  path_to_teacher = '/content/drive/MyDrive/train_model/lane_navigation_final.h5'\n",
        "  teacher = load_model(path_to_teacher)\n",
        "  teacher_results = predict_and_summarize(X_test_ppi, Y_test_ppi, teacher)\n",
        "  teacher.summary()\n",
        "\n",
        "  # Deploy trials and save results\n",
        "  result_file = '/content/drive/MyDrive/train_model/results.csv'\n",
        "\n",
        "  # Independant Variables\n",
        "  models = [distilled0_model, distilled1_model, distilled2_model, distilled3_model, distilled4_model, distilled5_model, distilled6_model, distilled7_model, distilled8_model, distilled9_model]\n",
        "  # temps parameters.\n",
        "  temps = [20, 10, 5, 2.5]\n",
        "\n",
        "  # For each model, and each temp, run 10 distilled trials\n",
        "  # refine the for loop, time complexity\n",
        "  for i, model in enumerate(models):\n",
        "    print('Now testing model...', str(i))\n",
        "    student = model()\n",
        "    student.summary()\n",
        "    for temp in temps:\n",
        "      print('Temp...', str(temp))\n",
        "      for trial in range(1,11):\n",
        "        print('Trial...', str(trial))\n",
        "\n",
        "        # Construct student model\n",
        "        student = model()\n",
        "\n",
        "        # Distill teacher to student\n",
        "        distill_teacher_to_student(student, teacher, temp, X_train_ppi, Y_train_ppi, X_valid_ppi, Y_valid_ppi)\n",
        "        distilled_path = '/content/drive/MyDrive/train_model/distilled'+ str(i) +'_trial'+str(trial)+'_temp'+str(temp)+'_model.h5'\n",
        "\n",
        "        # Save results row by row iteratively\n",
        "        student.save(distilled_path)\n",
        "        student_results = predict_and_summarize(X_test_ppi, Y_test_ppi, student)\n",
        "        result_row = [str(model), str(trial), str(temp)] + list(teacher_results) + list(student_results)\n",
        "        write_row_csv(result_row, result_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# change the data path on own google drive\n",
        "data_dir = '/content/drive/MyDrive/data/train_data/'"
      ],
      "metadata": {
        "id": "S-0Tzqa8Q3Tx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fef64bc-5c04-4385-ce5a-bb623ffa3cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}